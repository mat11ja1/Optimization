In order to avoid having to use any derivatives we decided to use the Golden section line search method. First problem is to be able to decide a good interval that is big enough to include the minimum but small enough to not give any numerical problems. To do this we started at two initial points [-10 10] and then checked that these will result in an acceptable value for each of the directions. If it is not acceptable for some direction we decrease the interval in that direction by a factor of 10 and if it is acceptable we check if increasing the interval by factor 2 in a direction will give a larger or smaller functional value, if  it is smaller we keep increasing the interval until the functional value gets larger and the end point is acceptable. We found this method to be successful for all our test. Another problem that would arise was when the function was not unimodal, the interval could sometimes skip past the minimum to converge to a local minimum. To keep this from happening we added a condition to check if it would be better to not take a step at all. With this condition we managed to find the minimum for all our tests. To begin with we ran the method until our interval became smaller than the tolerance, however this gave us some numerical problems for test functions where the minimum was on really large or small points. So instead we looked at the difference of the functional values of the end points for the interval as well as the functional value in the middle of the interval, to make sure we do not get convergence on two different points that just have the same functional value. With these modifications and the criterion we managed to get convergence for all the test functions that we ran. For the test function we got the minimal value -1 found in 0.0025s for [0,1] and -1 found in 0.001s for [1,0]. 
